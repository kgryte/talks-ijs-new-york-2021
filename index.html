<!doctype html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<meta http-equiv="x-ua-compatible" content="ie=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

	<title>Faster than NumPy | Talk | iJS New York, 2021</title>

	<meta name="description" content="NumPy is a foundational component of the PyData ecosystem, providing a high-performance numerical library on which countless image processing, machine learning, and data analytics tools are built in Python. Is it possible to bring the same power, performance, and robustness to JavaScript? In this talk, I’ll discuss our journey in trying to build such a library. I’ll dive deep into the weeds of performance profiling, hidden classes, cache-oblivious iteration, hardware optimization, and much more. I’ll show benchmarks showcasing how well JavaScript stacks up against the competition. And I’ll conclude by discussing where we go from here. So is it possible? Come to my talk to find out, as the answer may surprise you.">
	<meta name="author" content="Athan Reines">

	<meta name="apple-mobile-web-app-capable" content="yes">
	<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

	<!-- Icons -->
	<link rel="apple-touch-icon" sizes="180x180" href="apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
	<link rel="manifest" href="manifest.json">
	<link rel="mask-icon" href="safari-pinned-tab.svg" color="#5bbad5">
	<meta name="theme-color" content="#ffffff">

	<!-- Stylesheets -->
	<link rel="stylesheet" href="fonts/lato/latin/lato_light.css">
	<link rel="stylesheet" href="fonts/libre-baskerville/libre_baskerville.css">
	<link rel="stylesheet" href="fonts/font-awesome/fontawesome.css">

	<link rel="stylesheet" href="node_modules/reveal.js/dist/reset.css">
	<link rel="stylesheet" href="node_modules/reveal.js/dist/reveal.css">
	<link rel="stylesheet" href="node_modules/reveal.js/dist/theme/simple.css">
	<link rel="stylesheet" href="node_modules/reveal.js-appearance/plugin/appearance/appearance.css">

	<link rel="stylesheet" href="css/highlight.css">
	<link rel="stylesheet" href="css/animate.css">
	<link rel="stylesheet" href="css/main.css">
</head>
<body>
	<div class="reveal">

		<!-- Any section element inside of this container is displayed as a slide -->
		<div class="slides">

			<section id="conf-splash" data-background-transition="slide" data-background-image="img/conf_splash.png">
				<aside class="notes">
					(next slide)
				</aside>
			</section>

			<section id="title-slide" data-transition="slide-in slide-out" data-background-image="img/splash/cheetah_1920x1280.jpg">

				<div class="background-wrap">
					<div class="background right-trapezoid-background"></div>
				</div>

				<div class="grid">
					<h1 class="fragment title"><span class="animated skidRightBig">Faster than NumPy</span></h1>
					<h2 class="fragment subtitle"><span class="animated skidRightBig">High-performance numerical computation in JavaScript</span></h2>
				</div>

				<aside class="notes">
					<p>
						Hello and welcome to my talk! I'm Athan Reines, and, today, I'll be presenting <strong>Faster than NumPy: High-performance numerical computation in JavaScript</strong>.
				</aside>
			</section>

			<section id="about-me-splash-slide" data-transition="slide-in slide-out" data-background-image="img/splash/golden_gate_bridge.jpg">

				<div class="background-wrap">
					<div class="background right-trapezoid-background"></div>
				</div>

				<div class="grid">
					<h1 class="title"><span class="animated fadeIn" data-delay="500">About me.</span></h1>
				</div>

				<aside class="notes">
					<p>
						Before we begin, I want to provide a brief overview of my background to help motivate this talk and to provide a rationale for why you should even listen to me in the first place.
					</p>
				</aside>
			</section>

			<section id="about-me-slide">

				<div class="grid">
					<div class="fragment">
						<a href="https://www.quansight.com/"><img class="animated flipInX" data-src="img/quansight_logo.png" alt="Quansight" class="undecorated" height="70%" width="70%"></a>
					</div>

					<div class="fragment">
						<a href="https://labs.quansight.org/"><img class="animated flipInX" data-src="img/quansight_labs_logo.png" alt="Quansight Labs" class="undecorated" width="70%"></a>
					</div>

					<div class="fragment">
						<a href="https://data-apis.org/"><img class="animated flipInX" data-src="img/data_apis_logo.svg" alt="Data APIs" class="undecorated" height="40%" width="40%"></a>
					</div>

					<div class="fragment">
						<a href="https://stdlib.io/docs/api/latest"><img class="animated flipInX" data-src="img/stdlib_logo_banner.svg" alt="stdlib" class="undecorated"></a>
					</div>
				</div>

				<aside class="notes">
					<p>
						I work for Quansight, a software consulting company cofounded by Travis Oliphant, the primary original author of NumPy and founding contributor to SciPy.
					</p>
					<p>
						As a software consulting company, Quansight acts as an intermediary between companies and the open source ecosystems on which those companies depend. Most of the in-house expertise, and thus the consulting work, centers around the PyData stack: NumPy, SciPy, Numba, Dask, PyData Sparse, pandas, Jupyter, conda, and others.
					</p>
					<p>
						(next fragment)
					</p>
					<p>
						Under the same corporate umbrella as Quansight is the public benefit division Quansight Labs which consists of the developers, community managers, designers, and writers who actually create and maintain the open-source technologies mentioned earlier.
					</p>
					<p>
						(next fragment)
					</p>
					<p>
						The majority of my work at Quansight is as part of the Consortium for Python Data API standards, which is a Quansight Labs led initiative to develop API standards for array and dataframe libraries within the PyData ecosystem.
					</p>
					<p>
						The Consortium brings together core maintainers from NumPy, CuPy, Dask, Torch, TensorFlow, Apache Arrow, and others in order to create hardware agnostic specifications for commonly used APIs to facilitate interoperability between array and dataframe libraries and reduce ecosystem fragmentation.
					</p>
					<p>
						(next fragment)
					</p>
					<p>
						Also, as part of my work, I am a core maintainer of the open-source project, <a href="https://stdlib.io/docs/api/latest">stdlib</a>, a standard library for JavaScript and Node.js.
					</p>
					<p>
						One of the foremost goals of stdlib is to provide the equivalent of NumPy and SciPy for <strong>numerical</strong> and <strong>scientific</strong> computation on the web and in Node.js.
					</p>
					<p>
						Most of my work on stdlib focuses on developing APIs for high-performance numerical operations on multi-dimensional arrays in JavaScript and C--the precise subject of this talk. :)
					</p>
				</aside>
			</section>

			<section id="numpy-splash-slide" data-transition="slide-in fade-out">
				<div class="background middle-stripe-background"></div>
				<div class="grid">
					<img class="animated fadeIn slow" data-delay="500" data-src="img/numpy_logo.svg" href="NumPy logo">
				</div>

				<aside class="notes">
					<p>
						Given that this is a JavaScript conference and I don't want to assume that everyone attending this talk knows Python and is familiar with the PyData numerical computing landscape, I'd like to begin our discussion by providing a high-level introduction to NumPy and array computing.
					</p>
				</aside>
			</section>

			<section id="numpy-slide" data-transition="fade-in fade-out">

				<div class="background-wrap">
					<div class="background polygon-background-1"></div>
				</div>
				<div class="grid">
					<p class="fragment fade-in-then-out">
						<span class="animated fadeIn slow" data-delay="500">
							CPU-based library for performing numerical computation on multidimensional arrays.
						</span>
					</p>
					<p class="fragment">
						<span class="animated fadeIn" data-delay="500">
							ndarray
						</span>
					</p>
				</div>

				<aside class="notes">
					<p>
						(fragment)
					</p>
					<p>
						Originally written in 2005, NumPy is a CPU-based library for performing numerical computation on multidimensional arrays.
					</p>
					<p>
						Without the assistance of a multi-process library, NumPy operations are blocking, running on a single-core and executing synchronously in sequential order.
					</p>
					<p>
						I should note that NumPy is able to leverage parallelism through SIMD operations, depending on host architecture and compilation.
					</p>
					<p>
						However--and this is relevant for later discussion--while other libraries exist to address limitations in NumPy--for example, through the use of GPUs (CuPy), GPUs/TPUs (Torch/TensorFlow), or distributed computation (Dask), NumPy does not, by itself, enjoy any inherit advantages compared to a comparable library written in JavaScript by virtue of being written in and for Python.
					</p>
					<p>
						The same issues, such as single-threading and limited host memory, that are seen as limitations in JavaScript apply equally to Python, and thus NumPy, as well.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						The fundamental building block of NumPy is the <code>ndarray</code>, which is a data structure for describing multidimensional arrays.
					</p>
					<p>
						I'll discuss the technical aspects of ndarrays throughout this talk, but, before I do, we should probably ask what is so special about multidimensional arrays.
					</p>
				</aside>
			</section>

			<section id="ndarray-use-cases-splash-slide" data-background-image="img/splash/keyboard.jpg" data-transition="fade-in fade-out" data-transition-speed="fast">

				<div class="background-wrap">
					<div class="background right-trapezoid-background"></div>
				</div>
				<div class="grid">
					<h1>Demos</h1>
				</div>

				<aside class="notes">
					<p>
						I think the best way to demonstrate why ndarrays <strong>are</strong> special is to show examples of the types of applications made possible through the use of ndarrays.
					</p>
					<p>
						So to help motivate why, in a general sense, <code>ndarrays</code> are so useful, I want to briefly digress and start with a few demos of web applications which are using <code>ndarray</code> data structures to perform various computational tasks.
					</p>
				</aside>
			</section>

			<section id="falcon-demo-slide" data-transition="fade-in fade-out">

				<iframe data-src="https://vega.github.io/falcon/flights/"></iframe>

				<aside class="notes">
					<p>
						Most of us probably have some sense that multidimensional arrays are useful in traditional numerical and scientific computing fields, even if we don't typically work with them ourselves.
					</p>
					<p>
						We've undoubtedly heard of "big data", machine learning, and artificial intelligence and probably assume that they involve working with large datasets with potentially many dimensions.
					</p>
					<p>
						At university, we may have used MATLAB and taken a data science course on Coursera or somewhere else.
					</p>
					<p>
						So my first demo should not come as too much of a surprise in that it involves working with large datasets.
					</p>
					<p>
						Currently displayed is Falcon, a library for high-performance cross-filtering of large datasets directly in the browser.
					</p>
					<p>
						What is shown is a collection of histograms visualizing different facets of a 1 million flight dataset.
					</p>
					<p>
						Internally, Falcon is using an ndarray data structure to aggregate and bin the flight data in real-time as a user interacts with the graph brushes.
					<p>
						(play with brushes and demonstrate responsiveness)
					</p>
				</aside>
			</section>

			<section id="mikola-voxel-demo-slide" data-transition="fade-in fade-out">

				<iframe data-src="https://mikolalysenko.github.io/voxel-mipmap-demo/"></iframe>

				<aside class="notes">
					<p>
						The second demo is a project by Mikola Lysenko, which provides an interactive application for demonstrating texture mapping.
					</p>
					<p>
						Internally, Mikola uses ndarrays for processing the voxel data and creating meshes.
					</p>
					<p>
						(select a few examples from the dropdown and interact with one or two of the rendered objects)
					</p>
				</aside>
			</section>

			<section id="regl-cnn-demo-slide" data-transition="fade-in fade-out">

				<iframe data-src="https://erkaman.github.io/regl-cnn/src/demo.html"></iframe>

				<aside class="notes">
					<p>
						The third demo is a project by one of the regl developers demonstrating the application of convolutional neural networks to handwritten digit recognition.
					</p>
					<p>
						Internally, this demo uses ndarrays for implementing the convolutional neural network and performing various tensor operations.
					</p>
					<p>
						(draw a few digits)
					</p>
				</aside>
			</section>

			<section id="tensorflow-pacman-demo-slide" data-transition="fade-in fade-out">

				<iframe data-src="https://storage.googleapis.com/tfjs-examples/webcam-transfer-learning/dist/index.html"></iframe>

				<aside class="notes">
					<p>
						The next demo comes from the TensorFlow.js team.
					</p>
					<p>
						In this demo--which I won't play because I'm already using my web cam for this talk--one can train a neural network directly in the browser to recognize gestures in order to control pac man as pac man navigates a maze.
					</p>
					<p>
						Similar to NumPy, ndarrays are the fundamental data structure in TensorFlow.js underpinning all the numerical computations.
					</p>
				</aside>
			</section>

			<section id="real-time-kmeans-demo-slide" data-transition="fade-in fade-out">

				<div class="image-wrapper">
					<a href="https://observablehq.com/@kgryte/stdlib-real-time-k-means-clustering"><img src="img/observable_kmeans.png"></a>
				</div>

				<aside class="notes">
					<p>
						The next demo is an Observable notebook showcasing real-time k-means clustering.
					</p>
					<p>
						(click on screenshot and pray that the notebook dependencies resolve and the notebook loads)
					</p>
					<p>
						In this notebook, ndarrays are used in the clustering of two-dimensional datasets, as the data becomes available in real-time.
					</p>
					<p>
						(scroll bottom)
					</p>
					<p>
						(try to run the simulation)
					</p>
				</aside>
			</section>

			<!-- TODO: additional demos of ndarray use cases? -->

			<section id="multidimensional-array-splash-slide" data-background-image="img/splash/multiplication_tables.jpg" data-transition="slide-in fade-out">

				<div class="background-wrap">
					<div class="background left-trapezoid-background"></div>
				</div>
				<div class="grid">
					<h1 class="animated fadeIn slow" data-delay="500">Multidimensional arrays</h1>
				</div>

				<aside class="notes">
					<p>
						Now that we've gotten a sense as to the types of applications which utilize ndarrays--data visualization, three-dimensional rendering, gaming, neural networks and artificial intelligence, and, perhaps unsurprisingly, more traditional machine learning tasks such as clustering and classification--let's move on to the more technical aspects of their implementation.
					</p>
					<p>
						To start, we should ask "what is a multidimensional array?"
					</p>
					<p>
						Most of us have a working understanding of multidimensional arrays and their implementation, often within the context of a list of lists (or an array of arrays in JavaScript).
					</p>
					<p>
						I should note that I'll be using the terms "list of lists" and "array of arrays" interchangeably throughout this talk.
					</p>
					<p>
						(next slide)
					</p>
				</aside>
			</section>

			<!-- TODO: an animation displaying a generalized depiction of array of arrays -->

			<section id="array-of-arrays-slide" data-transition="fade-in">
				<div class="grid">

					<div class="code">
						<pre><code class="language-javascript" data-trim data-line-numbers="1-5|7-9|11-13|15-17|19-24">
arr = [
	[ 1, 2, 3 ],
	[ 4, 5, 6 ],
	[ 7, 8, 9 ]
];

// Get individual item:
v = arr[1][1];
// returns 5

// Get row:
row = arr[1];
// returns [ 4, 5, 6 ]

// Get column: (!!!)
col = [ arr[0][1], arr[1][1], arr[2][1] ];
// returns [ 2, 5, 8 ]

// Column-major:
arr = [
	[ 1, [ 2, [ 3,
	  4,   5,   6,
	  7 ], 8 ], 9 ]
];
						</code></pre>
					</div>

					<div class="text">
						<p class="fragment">
							Let \( n \) be the number of elements per dimension and \( d \) be the number of dimensions.
						</p>
						<ul>
							<li class="fragment">\( O(d) \) &mdash; data access</li>
							<li class="fragment">\( O(n^{d}d) \) &mdash; traversal</li>
							<li class="fragment">\( O(n^{d}) \) &mdash; slicing</li>
							<li class="fragment">\( O(n^{d-1}) \) &mdash; extra storage requirements</li>
						</ul>
					</div>

				</div>

				<aside class="notes">
					<p>
						Consider this example. Here, we have a list of three arrays, each with three items.
					</p>
					<p>
						Interpreted as a two-dimensional data structure, this would comprise a 3x3 matrix, where each row is represented by a nested list/array.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						To access an individual item, we index into each dimension, dereferencing nested lists/arrays until we reached the last dimension.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						For higher-dimensional arrays, to retrieve sub-vectors, matrices, and tensors, we perform a similar procedure, except that we stop dereferencing lists once we've reached the desired dimensionality.
					</p>
					<p>
						Here, we're accessing the vector representing the second row in our matrix.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Suppose, however, that we want to access the second column in our matrix. How do we do that?
					</p>
					<p>
						Unfortunately, accessing the second column is not as simple as dereferencing a single list.
					</p>
					<p>
						Instead, we need to dereference each row, retrieve the item in the desired column, and then copy to a new array.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Of course, if we wanted to optimize for column access, we could change how we store the data, such that items belonging to the same column are stored together.
					</p>
					<p>
						However, in both scenarios, optimizing data locality for one type of data access de-optimizes the other.
					</p>
					<p>
						In general, for an array of arrays approach to storing multidimensional data, we have the following performance characteristics.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Let \( n \) be the number of elements per dimension and \( d \) be the number of dimensions.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Data access scales linearly with the number dimensions, as we dereference pointers to nested blocks of memory.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Array traversal scales according to \( O(d n^{d}) \) and, importantly, is not guaranteed to be cache coherent.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Slicing (i.e., extracting a subarray) scales according to \( O(n^{d}) \) ).
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Lastly, storage requirements scale according to \( O(n^{d-1}) \) due to the need for intermediate arrays containing pointers.
					</p>
					<p>
						(next slide)
					</p>
				</aside>
			</section>

			<section id="implicit-arrays-splash-slide" data-background-image="img/splash/building_with_glass_window_array.jpg" data-transition="slide-in fade-out">

				<div class="background-wrap">
					<div class="background left-trapezoid-background"></div>
				</div>
				<div class="grid">
					<h1 class="animated fadeIn slow" data-delay="500">Implicit arrays</h1>
				</div>

				<aside class="notes">
					<p>
						We can address some of the theoretical shortcomings of arrays of arrays by using an <a href="https://en.wikipedia.org/wiki/Implicit_data_structure">implicit data structure</a>.
					</p>
					<p>
						An implicit data structure is one in which the position of each element conveys meaning and the relationship of that element to other elements.
					</p>
					<p>
						This is in contrast to an explicit data structure which uses pointers to describe an <emphasis>explicit</emphasis> relationship between elements (e.g., consider a linked list).
					</p>
					<p>
						(next slide)
					</p>
				</aside>
			</section>

			<!-- TODO: an animation converting an array of arrays schematic to an implicit array -->

			<section id="implicit-arrays-slide" data-transition="fade-in">
				<div class="grid">

					<div class="code">
						<pre><code class="language-javascript" data-trim data-line-numbers="1-5|7-9|11-13|15-17">
arr = [
	1, 2, 3,
	4, 5, 6,
	7, 8, 9
];

// Get individual item:
v = arr[ (1*3) + 1 ];
// returns 5

// Get row:
row = [arr[(1*3)+0], arr[(1*3)+1], arr[(1*3)+2]];
// returns [ 4, 5, 6 ]

// Get column:
col = [arr[(0*3)+1], arr[(1*3)+1], arr[(2*3)+1]];
// returns [ 2, 5, 8 ]
						</code></pre>
					</div>

					<div class="text">
						<p class="fragment">
							Let \( n \) be the number of elements per dimension, \( d \) be the number of dimensions, and \( B \) be the cache line size.
						</p>
						<ul>
							<li class="fragment">\( O(1) \) &mdash; data access</li>
							<li class="fragment">\( O(\frac{n^d}{B}) \) &mdash; traversal</li>
							<li class="fragment">\( O(\frac{n^d}{B}) \) &mdash; slicing</li>
							<li class="fragment">\( O(0) \) &mdash; extra storage requirements</li>
						</ul>
					</div>

				</div>

				<aside class="notes">
					<p>
						To convert our previous array of arrays to an implicit data structure, we do away with nested arrays and, instead, store all items in a single flat list/array.
					</p>
					<p>
						This is an implicit data structure as the ordering tells us something about the relationship of each item with the others.
					</p>
					<p>
						Notably, as we progress along the array, we traverse rows.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Beside the data layout, there are a few other key differences of this data structure compared to an array of arrays.
					</p>
					<p>
						First, in order to access a single item, we need to perform some arithmetic.
					</p>
					<p>
						In order to get the second item in the second row, we first need to multiply the desired row number (using zero-based indexing) by the number of elements in the row and then add the desired column number (again, using zero-based indexing).
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Retrieving a row is not as simple as the list of lists implementation.
					</p>
					<p>
						We need to apply the same formula we used for accessing a single element to each element in the desired row.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						That same formula can also be applied for retrieving a column, and, thus, avoids the dereferencing overhead implicit in the array of arrays implementation.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						In general, for an implicit array approach to storing multidimensional data, we have the following performance characteristics.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Let \( n \) be the number of elements per dimension, \( d \) be the number of dimensions, and \( B \) be the cache line size.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Data access is effectively \( O(1) \), given that performing arithmetic is generally cheaper than dereferencing memory addresses.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						For traversal, we lose a factor of \( d \), and, importantly, traversal is more likely to be cache coherent.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Similar to traversal, slicing scales according to \( O(n^d) \), being partially offset by improved data locality.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Lastly, an implicit array does not require extra storage, as we no longer need intermediate arrays containing pointers.
					</p>
					<p>
						In summary, implicit arrays have better theoretical performance guarantees than their array of arrays counterparts.
					</p>
					<p>
						(next slide)
					</p>
				</aside>
			</section>

			<section id="strided-arrays-splash-slide" data-background-image="img/splash/building_from_below.jpg" data-transition="slide-in fade-out">

				<div class="background-wrap">
					<div class="background left-trapezoid-background"></div>
				</div>
				<div class="grid">
					<h1 class="animated fadeIn slow" data-delay="500">Strided arrays</h1>
				</div>

				<aside class="notes">
					<p>
						Implicit arrays are limited in two aspects: (1) their fixed nature and (2) inefficient slicing.
					</p>
					<p>
						To overcome, these limitations we can generalize the mapping of a multidimensional array to a linear layout via <strong>strided arrays</strong>.
					</p>
					<p>
						(next slide)
					</p>
				</aside>
			</section>

			<section id="strided-arrays-slide" data-transition="fade-in">
				<div class="grid">

					<div class="code">
						<pre><code class="language-javascript" data-trim data-line-numbers="1-5|7-8|9|10|12-14|16-20|20-24">
x = [
	1, 2, 3,
	4, 5, 6,
	7, 8, 9
];

// Define meta data:
shx = [ 3, 3 ]; // shape
ox = 0;         // offset
sx = [ 3, 1 ];  // strides (row-major/lexicographic)

// Get individual item:
v = x[ (1*sx[0]) + (1*sx[1]) + ox ];
// returns 5

// Define row:
shr = [ shx[1] ];     // [ 3 ]
sr = [ sx[1] ];       // [ 1 ]
or = (1*sx[0]) + ox;  // 3

// Define column:
shc = [ shx[0] ];     // [ 3 ]
sc = [ sx[0] ];       // [ 3 ]
oc = (1*sx[1]) + ox;  // 1
						</code></pre>
					</div>

					<div class="text">
						<p class="fragment">
							\[ \textrm{index}(x_{i_0 i_1 \dots i_{d-1}}) = o + \sum^{d-1}_{k = 0} s_k i_k \]

							where \( d \) is the number of dimensions, \( o \) is the offset, \( s_k \) are the strides, and \( i_k \) are the dimension subscripts.
						</p>
						<p class="fragment">
							Let \( n \) be the number of elements per dimension, \( d \) be the number of dimensions, and \( B \) be the cache line size.
						</p>
						<ul>
							<li class="fragment">\( O(1) \) &mdash; data access</li>
							<li class="fragment">\( O(\frac{n^d}{B}) \) &mdash; traversal</li>
							<li class="fragment">\( O(d) \) &mdash; slicing</li>
							<li class="fragment">\( O(d) \) &mdash; extra storage requirements</li>
						</ul>
					</div>

				</div>

				<aside class="notes">
					<p>
						A strided array generalizes an implicit array by explicitly defining meta data (aka, a <strong>dope vector</strong>) describing the data layout.
					</p>
					<p>
						Similar to the previous examples, we'll define a single flat array containing the elements of our multidimensional array.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Next, we'll define meta describing the data layout.
					</p>
					<p>
						First, we define the shape of our array. In this case, a three-by-three matrix.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Next, we define an offset which tells us the location of the first indexed element in the underlying flat array. In this case, we set the offset to the first element.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Next, we define strides which tell us how many elements in the underlying flat array we need to move a data pointer (via <strong>dead reckoning</strong>) until we reach the next item.
					</p>
					<p>
						In this case, to iterate to the next row, we need to skip three elements. To iterate to the next column, we simply move to the next element.
					</p>
					<p>
						At this point, the shape, strides, and offset meta data allow us to completely describe our two-dimensional matrix and can be generalized to multidimensional arrays having an arbitrary number of dimensions (aka, rank).
					</p>
					<p>
						I should note, however, that depending on the language, we may need additional meta data, such as the underlying array data type, in order to correctly resolve item memory locations and interpret the item value.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						To retrieve an individual element, we apply a similar formula as for implicit arrays, substituting in our strides and adding an offset term.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						To create a row slice, we can do as before with implicit arrays and explicitly extract values to a new array, <strong>or</strong> we can create a "view" over the flat array by defining meta data describing the row.
					</p>
					<p>
						Here, in order to access the second row, we define the shape to be the number of columns, the strides to be the column stride, and the offset to point to the first element in the second row.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Similarly, we can create a view for the second column by defining the shape to be the number of rows, the strides to be the row stride, and the offset to point to the first element in the second column.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						We can generalize mapping the subscripts of an item in a multidimensional array to an item in the underlying flat array according to the following formula, where \( d \) is the number of dimensions, \( o \) is the offset, \( s_k \) are the strides, and \( i_k \) are the dimension subscripts.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						In general, we have the following performance characteristics for strided arrays.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Let \( n \) be the number of elements per dimension, \( d \) be the number of dimensions, and \( B \) be the cache line size.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Data access is effectively \( O(1) \), same as for implicit arrays.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Traversal is the same as for implicit arrays, benefiting from data locality, although this depends heavily on the strides.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Where strided arrays can significantly depart from implicit arrays is in slicing, as, by defining meta data describing the slice, we can create a view over the underlying collection. Accordingly, slicing scales according to the number of dimensions.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Lastly, when compared to implicit arrays, strided arrays have extra storage requirements which scale with the number of dimensions.
					</p>
					<p>
						In summary, in exchange for slightly larger memory requirements, strided arrays offer considerably more flexibility, and thus utility, than their implicit array counterparts.
					</p>
					<p>
						(next slide)
					</p>
				</aside>
			</section>

			<section id="strided-array-tricks-slide" data-transition="fade-in">
				<div class="grid">

					<div class="schematics grid">
						<div data-animate data-src="img/array_reverse_schematic.svg">
							<!--
							{
								"setup": [
									{
										"element": "#svg-reverse-array-arrow, #svg-reverse-array2",
										"modifier": "attr",
										"parameters": [ {"class": "fragment", "data-fragment-index": "0"} ]
									}
								]
							}
							-->
						</div>
						<div data-animate data-src="img/array_transpose_schematic.svg">
							<!--
							{
								"setup": [
									{
										"element": "#svg-transpose-matrix1",
										"modifier": "attr",
										"parameters": [ {"class": "fragment", "data-fragment-index": "1"} ]
									},
									{
										"element": "#svg-transpose-arrow, #svg-transpose-matrix2",
										"modifier": "attr",
										"parameters": [ {"class": "fragment", "data-fragment-index": "2"} ]
									}
								]
							}
							-->
						</div>
						<div data-animate data-src="img/array_reshape_schematic.svg">
							<!--
							{
								"setup": [
									{
										"element": "#svg-reshape-matrix1",
										"modifier": "attr",
										"parameters": [ {"class": "fragment", "data-fragment-index": "3"} ]
									},
									{
										"element": "#svg-reshape-arrow, #svg-reshape-tensor1",
										"modifier": "attr",
										"parameters": [ {"class": "fragment", "data-fragment-index": "4"} ]
									}
								]
							}
							-->
						</div>
						<div data-animate data-src="img/array_subarray_schematic.svg">
							<!--
							{
								"setup": [
									{
										"element": "#svg-subarray-matrix1",
										"modifier": "attr",
										"parameters": [ {"class": "fragment", "data-fragment-index": "5"} ]
									},
									{
										"element": "#svg-subarray-arrow, #svg-subarray-matrix2",
										"modifier": "attr",
										"parameters": [ {"class": "fragment", "data-fragment-index": "6"} ]
									}
								]
							}
							-->
						</div>
					</div>

					<div class="code">
						<pre><code class="language-javascript" data-trim data-line-numbers="1-2|4-6|9-10|12-13|16-17|19-21|24-25|27-29">
// Reverse an array...
shape = [8]; strides = [1]; offset = 0;

// Negate strides and adjust offset:
strides[0] *= -1;
offset = 7;


// Matrix transpose...
shape = [3, 3]; strides = [3, 1]; offset = 0;

// Swap strides (and dimensions):
strides = [1, 3];


// Reshape an array...
shape = [3, 3]; strides = [3, 1]; offset = 0;

// Update shape and strides:
shape = [3, 1, 3];
strides = [3, 3, 1];


// Access a subarray (slice)...
shape = [3, 3]; strides = [3, 1]; offset = 0;

// Update shape and offset:
shape = [2, 2];
offset = 4;
						</code></pre>
					</div>

				</div>

				<aside class="notes">
					<p>
						To help demonstrate their utility, let's consider a few operations which we effectively get for free when using strided arrays.
					</p>
					<p>
						First, suppose we want to reverse a one-dimensional strided array. We define a shape, strides, and an offset as shown previously.
					</p>
					<p>
						(next fragment)
					<p>
						To realize the reverse of this array, we need only negate the stride and adjust the offset.
					</p>
					<p>
						According to our index formula from the previous slide, accessing the first element of our reversed array will access the last element of the underlying collection of items.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Next, suppose we want to take the transpose of a three-by-three matrix.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						To realize the transpose, we simply swap the strides (and, more generally, the dimensions).
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Next, suppose we want to reshape an array from a three-by-three matrix to a three dimensional tensor containing three one-by-three matrices.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						To derive an array with a different shape (and the same number of total elements), we update the shape and strides, without needing to touch the underlying data--something which is not readily achievable when using an array of arrays.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Lastly, suppose we want to access a two-by-two subarray within our three-by-three matrix.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						To do so, we update the shape and adjust our offset, and, using the index formula shown earlier, we'll only access those elements highlighted in blue.
					</p>
					<p>
						These are only a few examples of how strided arrays are rather useful when working with multidimensional data, as they allow fast slicing and manipulation of views atop a flat underlying data store.
					</p>
					<p>
						(next slide)
					</p>
				</aside>
			</section>

			<!-- TODO: consider adding a schematic demonstrating tiling (with applications to broadcasting) -->

			<section id="ndarray-conceptual-diagram-slide" data-transition="fade-in slide-out">

				<!-- NOTE: the following are non-presentation elements used for driving the SVG animations -->
				<span class="fragment"></span>
				<span class="fragment"></span>
				<span class="fragment"></span>
				<span class="fragment"></span>
				<span class="fragment"></span>
				<span class="fragment"></span>

				<div class="grid">
					<div data-animate data-src="img/ndarray_schematic.svg">
						<!--
						{
							"setup": [
								{
									"element": "#svg-from-data-type-arrow, #svg-from-array-item-arrow, #svg-array-item-object",
									"modifier": "attr",
									"parameters": [ {"class": "fragment", "data-fragment-index": "5"} ]
								},
								{
									"element": "#svg-array-item",
									"modifier": "attr",
									"parameters": [ {"class": "fragment", "data-fragment-index": "4"} ]
								},
								{
									"element": "#svg-to-data-type-arrow, #svg-data-type-box",
									"modifier": "attr",
									"parameters": [ {"class": "fragment", "data-fragment-index": "3"} ]
								},
								{
									"element": "#svg-array-with-meta-data",
									"modifier": "attr",
									"parameters": [ {"class": "fragment", "data-fragment-index": "2"} ]
								},
								{
									"element": "#svg-array-header",
									"modifier": "attr",
									"parameters": [ {"class": "fragment", "data-fragment-index": "1"} ]
								},
								{
									"element": "#svg-array-items",
									"modifier": "attr",
									"parameters": [ {"class": "fragment", "data-fragment-index": "0"} ]
								}
							]
						}
						-->
					</div>
				</div>

				<aside class="notes">
					<p>
						Now that we've discussed strided arrays, we can return our attention to NumPy and its fundamental data structure: the <strong>ndarray</strong>.
					<p>
						(fragment)
					</p>
					<p>
						An ndarray is collection of "items", where each item has the same data type.
					</p>
					<p>
						And as a corollary, an ndarray is a <strong>homogeneous</strong> data structure, in which every item occupies a memory block of the same size and in which all blocks are interpreted in exactly the same way.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Simply having a collection of items is not sufficient, however, to perform operations on multidimensional data. We need to specify meta data describing the data location (i.e., offset) and layout (i.e., shape and strides).
					</p>
					<p>
						(fragment)
					</p>
					<p>
						By associating the meta data with the collection of items, we are able to fully describe and interface with an ndarray.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						How each item in the array is to be interpreted is specified by a separate data-type object (or identifier) as referenced by the ndarray meta data.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Using the meta data, we can locate and access an individual item within the collection.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						In Python (and in un-optimized JavaScript), an accessed item is "boxed", being associated with meta data and interpreted according to the previously mentioned data type object.
					</p>
					<p>
						All of this comprises the conceptual model of an ndarray.
					</p>
					<p>
						As I hope is evident from previous slides, at its essence, NumPy's ndarray is a fancy wrapper around a strided array, with some additional meta data.
					</p>
					<p>
						(next slide)
					</p>
			</section>

			<section id="numpy-perf-slide">

				<div class="grid">
					<div class="fragment">
						<h2 class="animated flipInX">Vectorization</h2>
					</div>

					<div class="fragment">
						<h2 class="animated flipInX">Parallelization</h2>
					</div>

					<div class="fragment">
						<h2 class="animated flipInX">Hardware Optimization</h2>
					</div>

					<div class="fragment">
						<h2 class="animated flipInX">Broadcasting</h2>
					</div>
				</div>

				<aside class="notes">
					<p>
						So how does NumPy leverage ndarrays to unlock better performance? There are four ways.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						First, NumPy utilizes vectorization, providing interfaces such as the universal function interface (aka "ufunc") which operate on ndarrays, rather than relying on users to perform element-wise iteration in userland.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Second, NumPy takes advantage of SIMD operations for parallelization (i.e., operating on multiple elements within a strided array at the same time).
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Third, NumPy binds to hardware optimized libraries for various numerical computing tasks, such as using OpenBLAS for linear algebra.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Lastly, NumPy supports broadcasting semantics (i.e., the ability to tile a lower dimensional array to a higher dimension without copying data).
					</p>
					<p>
						For example, when multiplying a matrix by scalar, NumPy does not instantiate a second matrix with the same dimensions as the first and set every element to a value equal to the scalar.
					</p>
					<p>
						Instead, NumPy virtually repeats a scalar by simply creating a single element ndarray with modified shape and strides.
					</p>
					<p>
						In short, broadcasting enables better performance by avoiding data copies.
					</p>
				</aside>
			</section>

			<section id="stdlib-splash-slide" data-transition="slide-in fade-out">
				<div class="grid">
					<div class="image-wrapper">
						<a href="https://stdlib.io/docs/api/latest"><img class="animated fadeIn slow" data-delay="500" data-src="img/stdlib_logo_banner.svg" href="stdlib logo"></a>
					</div>
				</div>

				<aside class="notes">
					<p>
						So what does all this mean for JavaScript, and is it possible to leverage the same four secrets to NumPy performance in JavaScript and Node.js?
					</p>
					<p>
						As I alluded to at the start of this talk, I contribute to a project with this explicit goal: stdlib.
					</p>
					<p>
						And, as much as possible, stdlib tries to emulate NumPy in various respects.
					</p>
					<p>
						First and foremost, stdlib utilizes ndarrays for its fundamental data structure for operating on multidimensional arrays.
					</p>
					<p>
						(next slide)>
					</p>
					<p>
						------------
					</p>
					<p>
						(click on the logo and navigate to stdlib/ndarray/array)
					</p>
					<p>
						A few notes:
					</p>
					<ul>
						<li>generic ndarray creation API</li>
						<li>can create fresh arrays or views</li>
						<li>returned object can be JSON serialized for transfer over wire (see examples)</li>
					</ul>
					<p>
						(navigate to stdlib/ndarray/array-ctor)
					</p>
					<p>
						A few notes:
					</p>
					<ul>
						<li>lower level API</li>
						<li>highlight set/get APIs</li>
						<li>highlight accessible C APIs for use in Node.js native add-ons and elsewhere</li>
					</ul>
					<p>
						Building on the ndarray, we are currently working on vectorized interfaces for ndarray operations.
					</p>
					<p>
						For example, we've recently started adding the equivalent of universal functions interfaces to the project.
					</p>
					<p>
						(navigate to stdlib/math/special/abs)
					</p>
					<p>
						A few notes:
					</p>
					<ul>
						<li>can operate on numbers, array-like objects, and ndarrays</li>
						<li>by default, return an new array</li>
						<li>an "assign" API for mutating a previously allocated array to allow for memory reuse</li>
					</ul>
					<p>
						For hardware optimization, we've been slowly adding BLAS interfaces for linear algebra computations.
					</p>
					<p>
						(navigate to stdlib/blas/base/daxpy)
					</p>
					<p>
						BLAS interfaces are lower level interfaces for operating on contiguous strided array data.
					</p>
					<p>
						Similar to NumPy, we've added bindings to OpenBLAS for hardware optimized linear algebra routines when compiled and running in Node.js.
					</p>
					<p>
						And similar to the ndarray constructor interface earlier, we also provide C APIs for interfacing with these APIs in Node.js native add-ons.
					</p>
					<p>
						In terms of parallelization, we do not currently leverage SIMD, but it is something we'd like to add in the future.
					</p>
					<p>
						And in terms of broadcasting, we've recently started adding broadcasting support, but this is still very much a work in progress.
					</p>
					<p>
						(next slide)
					</p>
				</aside>
			</section>

			<section id="stdlib-ndarray-slide" data-transition="fade-in">
				<div class="grid">

					<div class="code">
						<pre><code class="language-javascript" data-trim data-line-numbers="1|3-7|9-11|13-15|17-19|21-23|25-27|29-31|33-35|37-38|40-42|44-46|48-53">
import array from '@stdlib/ndarray-array';

// Create a 4-dimensional array:
const arr = array({
    'dtype': 'float32',
    'shape': [ 3, 3, 3, 3 ]
});

// Retrieve the array shape:
const shape = arr.shape;
// returns [ 3, 3, 3, 3 ]

// Retrieve the array strides:
const strides = arr.strides;
// returns [ 27, 9, 3, 1 ];

// Retrieve the array offset:
const offset = arr.offset;
// returns 0

// Retrieve the array dtype:
const dtype = arr.dtype;
// returns 'float32'

// Retrieve the underlying array data:
const data = arr.data;
// returns &lt;Float32Array&gt;[ 0, ..., 0 ]

// Retrieve the array byte length:
const byteLength = arr.byteLength;
// returns 324

// Retrieve an array value:
let v = arr.get( 1, 2, 1, 2 );
// returns 0.0

// Set an array value:
arr.set( 1, 2, 1, 2, 10.0 );

// Retrieve the array value:
v = arr.get( 1, 2, 1, 2 );
// returns 10.0

// Serialize as JSON:
const json = arr.toJSON();
// returns {"type":"ndarray","dtype":"float32","flags":{},"order":"row-major","shape":[3,3,3,3],"strides":[27,9,3,1],"data":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]}

// Create a 2x2 matrix:
const arr2 = array([
	[ 1.0, 2.0 ],
	[ 3.0, 4.0 ]
]);
// returns &lt;ndarray&gt;[ 1.0, 2.0; 3.0, 4.0 ]
						</code></pre>
					</div>

					<div class="text">
						<h2>
							ndarray
						</h2>
					</div>

				</div>

				<aside class="notes">
					<p>
						(introducing the ndarray)
					</p>
					<p>
						To begin working with ndarrays, one can important the following package...
					</p>
					<p>
						(continue stepping through the code example)
					</p>
				</aside>
			</section>

			<section id="stdlib-vectorization-slide" data-transition="fade-in">
				<div class="grid">

					<div class="code">
						<pre><code class="language-javascript" data-trim data-line-numbers="1-2|4-6|8-10|12-14|16-18|20-22|24-28|30-31|33-44">
import array from '@stdlib/ndarray-array';
import abs from '@stdlib/math-special-abs';

// Create a one-dimensional vector:
let x = array([ -1.0, -2.0 ]);
// returns &lt;ndarray&gt;[ -1.0, -2.0 ]

// Retrieve the shape:
let shape = x.shape;
// returns [ 2 ]

// Retrieve the dtype:
let dtype = x.dtype;
// returns 'float64'

// Compute the absolute value for each element:
let y = abs( x );
// returns &lt;ndarray&gt;[ 1.0, 2.0 ]

// Retrieve the shape:
shape = y.shape;
// returns [ 2 ]

// Define an output array:
y = array({
	'shape': [ 4, 2 ]
});
// returns &lt;ndarray&gt;[ 0.0, 0.0; 0.0, 0.0; 0.0, 0.0; 0.0, 0.0 ]

// Broadcast results across rows:
abs.assign( x, y );

// Retrieve values:
let v = y.get(0, 0);
// returns 1.0

v = y.get(0, 1);
// returns 2.0

v = y.get(1, 0);
// returns 1.0

v = y.get(3, 1);
// returns 2.0
						</code></pre>
					</div>

					<div class="text">
						<h2>
							Vectorization and Broadcasting
						</h2>
					</div>

				</div>

				<aside class="notes">
					<p>
						Okay, so there's an ndarray API. But what can you do with it?
					</p>
					<p>
						Similar to NumPy, stdlib provides vectorized interfaces for performing element-wise operations on multidimensional arrays (in NumPy lingo, these are "ufuncs", or "universal functions")--although, I should state that this is very much a work in progress.
					</p>
					<p>
						Apart from its bindings to hardware optimized libraries, NumPy's internals are essentially a bunch of for-loops, enhanced with SIMD, written in C.
					</p>
					<p>
						stdlib is no different, in that, internally, stdlib tries to delegate to optimized loops for iterating over ndarray elements.
					</p>
					<p>
						In the browser, these loops are implemented in JavaScript, and, in Node.js, these loops are written in C and accessed through native add-ons.
					</p>
					<p>
						As an example of how to use vectorized APIs, consider the use case of computing the element-wise absolute value.
					</p>
					<p>
						To start, we begin by importing two packages: one to create an ndarray and another to compute the absolute value.
					</p>
					<p>
						(continue walking through the code example)
					</p>
				</aside>
			</section>

			<section id="stdlib-blas-slide" data-transition="fade-in">
				<div class="grid">

					<div class="code">
						<pre><code class="language-javascript" data-trim data-line-numbers="1-2|4-6|8-10|12-13|15-24|26-28|30-32|34-36|38-40|42-43|45-55|57-59|61-63">
import array from '@stdlib/ndarray-array';
import ddot from '@stdlib/blas/ddot';

// Create two one-dimensional vectors:
let x = array([ 1.0, 2.0, 3.0, 4.0 ]);
let y = array([ 5.0, 6.0, 7.0, 8.0 ]);

// Compute the dot product:
let v = ddot(x, y);
// returns 70

// Import a lower-level ndarray constructor:
import ndarray from '@stdlib/ndarray-ctor';

// Create a reverse view atop `y`:
let yr = ndarray(
	y.dtype,
	y.data,
	y.shape,
	[-1],
	y.length-1,
	y.order
);
// returns &lt;ndarray&gt;[ 8.0, 7.0, 6.0, 5.0 ]

// Retrieve the first element:
v = yr.get(0);
// returns 8.0

// Retrieve the underlying data:
let data = yr.data;
// returns &lt;Float64Array&gt;[ 5.0, 6.0, 7.0, 8.0 ]

// Confirm that `yr` is a view:
let bool = ( y.data === yr.data );
// returns true

// Compute the dot product with the reversed vector:
v = ddot(x, yr);
// returns 60

// Import a lower-level BLAS interface:
import daxpy from '@stdlib/blas-base-daxpy';

// Compute `y = a*x + y`:
daxpy.ndarray(
	x.length,
	5.0,
	x.data,
	x.strides[ 0 ],
	x.offset,
	y.data,
	y.strides[ 0 ],
	y.offset
);

// Retrieve the underlying data of `y`:
data = y.data;
// returns &lt;ndarray&gt;[ 10, 16, 22, 28 ]

// Compute the dot product with the reversed vector:
v = ddot(x, yr);
// returns 160
						</code></pre>
					</div>

					<div class="text">
						<h2>
							Hardware Optimization
						</h2>
					</div>

				</div>

				<aside class="notes">
					<p>
						As I mentioned previously, another key ingredient to NumPy's performance is its use of hardware optimized libraries, such as OpenBLAS, for fast CPU-based computation.
					</p>
					<p>
						And so, following in the footsteps of NumPy--and still a work-in-progress--stdlib includes bindings to BLAS interfaces for hardware optimized linear algebra routines when compiled and running in Node.js.
					</p>
					<p>
						As an example, consider the computation of the dot product.
					</p>
					<p>
						As in the previous examples, we'll start by importing stdlib packages.
					</p>
					<p>
						(continue stepping through the example)
					</p>
				</aside>
			</section>

			<section id="perf-comparison-slide" data-transition="slide-in fade-out">
				<div class="grid">
					<div class="fragment">
						<img class="animated flipInX" data-src="img/perf_ndarray_ndims_1_contiguous.svg" alt="Performance results" class="undecorated" width="100%">
					</div>

					<div class="fragment">
						<img class="animated flipInX" data-src="img/perf_ndarray_ndims_3_contiguous.svg" alt="Performance results" class="undecorated" width="100%">
					</div>

					<div class="fragment">
						<img class="animated flipInX" data-src="img/perf_ndarray_ndims_3_noncontiguous.svg" alt="Performance results" class="undecorated" width="100%">
					</div>

					<div class="fragment">
						<img class="animated flipInX" data-src="img/perf_array_like_ndims_1_contiguous.svg" alt="Performance results" class="undecorated" width="100%">
					</div>
				</div>

				<aside class="notes">
					<p>
						Okay. So it seems stdlib either has, or is working toward, comparable functionality to NumPy. But what about performance?
					</p>
					<p>
						(fragment)
					</p>
					<p>
						First graph: computing the element-wise absolute value over a one-dimensional ndarray with contiguous data.
					</p>
					<p>
						Explain various chart aspects: axes, legend, the higher the bar the better. Note that the y-axis is a log-scale, which eases visualization of results, but visually obscures the magnitude in performance difference.
					</p>
					<p>
						Takeaway: mostly within the same order of magnitude, but not as performant across the board.
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Okay. So what about multdimensional data? In this second graph, I'm showing results for element-wise computation of the absolute value for a three dimensional ndarray with contiguous data.
					</p>
					<p>
						The results effectively the same as for the previous set of benchmarks, which is not unexpected in that a higher-dimensional contiguous array can be treated equivalent to a one-dimensional array for element-wise computation.
					<p>
						(fragment)
					</p>
					<p>
						Okay. So what about non-contiguous data? In this third graph, I'm showing results for element-wise computation of the absolute value for a three dimensional ndarray with non-contiguous data.
					</p>
					<p>
						With non-contiguous data, cannot use simple loops, but need to either copy to contiguous or use cache oblivious (i.e., block) algorithms.
					</p>
					<p>
						Takeaway: results are better than the previous sets of benchmarks, especially for larger arrays; however, although within striking distance, can not yet match NumPy performance.
					</p>
					<p>
						Why? There are two reasons: (1) NumPy uses SIMD allowing it to operate on multiple array elements at once. (2) Especially, for shorter arrays, calling into native add-ons is relatively expensive, requiring the marshalling and unmarshalling of ndarray data as one cross the bridge from JavaScript to C.
					</p>
					<p>
						There are also additional issues with V8 attempting to be--arguably--too clever with how it handles initial typed array memory allocation, leading to performance cliffs when accessing typed array data from within native add-ons.
					<p>
						(fragment)
					</p>
					<p>
						For sake of comparison, in this fourth graph, I'm showing results for element-wise computation of the absolute value for a one-dimensional array-like object (i.e., an untyped generic array in JavaScript and a list in Python) with contiguous data.
					</p>
					<p>
						Finally, we've beaten NumPy! The main reason for the observed performance difference is that, when provided a value which is not an ndarray, NumPy first converts that value to an ndarray before performing element-wise computations. In stdlib, no such copy occurs.
					</p>
					<p>
						(next slide)
					</p>
				</aside>
			</section>

			<section id="conclusions-slide" data-transition="slide-in fade-out">
				<div class="grid">
					<h2 class="fragment">
						<span class="animated fadeIn slow" data-delay="500">Not (yet) faster than NumPy</span>
					</h2>
				</div>

				<aside class="notes">
					<p>
						So where does this leave us?
					</p>
					<p>
						(fragment)
					</p>
					<p>
						Not (yet) faster than NumPy.
					</p>
					<p>
						However, I am optimistic for the future. I think there are three keys areas for growth.
					</p>
					<p>
						First, taking advantage of data parallelization (i.e., SIMD). WebAssembly could help in this regard, given the relatively recent addition of SIMD support.
					</p>
					<p>
						Second, reducing the Node.js native add-on overhead of calling from JavaScript into C. Node.js core devs are aware of this overhead, and I expect this to improve over time.
					</p>
					<p>
						Third, addressing some of the V8 quirks, such as array allocation strategies, that trigger performance cliffs. This is a bit harder to address, but as numerical computation on the web becomes more common, I'd expect that we'll figure out workarounds which address some of the optimized use cases that V8 is targeting, while not negatively impacting other use cases where such optimizations are not desired.
					</p>
				</aside>
			</section>

			<section id="thank-you-slide" data-transition="fade-in slide-out" data-background-image="img/splash/mountains_with_fog_1920x1280.jpg">
				<div class="grid">
					<div class="content">
						<h1><span class="animated fadeIn slow" data-delay="500">Thank you.</span></h1>
						<nav class="author-links">
							<ul class="animated fadeIn slow" data-delay="1000">
								<li>
									<a href="https://github.com/kgryte"><i class="fa fa-github"></i> Athan Reines</a>
								</li>
								<li>
									<a href="https://twitter.com/kgryte"><i class="fa fa-twitter"></i> @kgryte</a>
								</li>
								<li>
									<a href="https://twitter.com/stdlibjs"><i class="fa fa-twitter"></i> @stdlibjs</a>
								</li>
							</ul>
						</nav>
					</div>
				</div>

				<aside class="notes">
					<p>
						And with that, I'd like to conclude this talk. Thank you for attending. I hope it has been informative. :)
					</p>
					<p>
						If you want to know more, you can find me on <a href="https://github.com/kgryte">GitHub</a> and Twitter.
					</p>
					<p>
						I'm happy to take any questions at this time.
					</p>
				</aside>
			</section>

			<section>
				<aside class="notes">
					(next slide)
				</aside>
			</section>

			<section id="numpy-strided-loops-slide-1">
				<div class="grid">
					<div class="code">
						<pre><code class="language-c" data-trim data-line-numbers="true">
#define BINARY_DEFS\
    char *ip1 = args[0], *ip2 = args[1], *op1 = args[2];\
    npy_intp is1 = steps[0], is2 = steps[1], os1 = steps[2];\
    npy_intp n = dimensions[0];\
    npy_intp i;\

#define BINARY_LOOP_SLIDING\
    for(i = 0; i < n; i++, ip1 += is1, ip2 += is2, op1 += os1)

/** (ip1, ip2) -> (op1) */
#define BINARY_LOOP\
    BINARY_DEFS\
    BINARY_LOOP_SLIDING
						</code></pre>
					</div>
				</div>

				<aside class="notes">

				</aside>
			</section>

			<section id="numpy-strided-loops-slide-2">

				<div class="grid">
					<div class="code">
						<pre><code class="language-c" data-trim data-line-numbers="true">
/**begin repeat
 * Float types
 *  #type = npy_float, npy_double#
 *  #TYPE = FLOAT, DOUBLE#
 *  #c = f, #
 *  #C = F, #
 */
/**begin repeat1
 * Arithmetic
 * # kind = add, subtract, multiply, divide#
 * # OP = +, -, *, /#
 * # PW = 1, 0, 0, 0#
 */
NPY_NO_EXPORT void NPY_CPU_DISPATCH_CURFX(@TYPE@_@kind@)
(char **args, npy_intp const *dimensions, npy_intp const *steps, void *NPY_UNUSED(func))
{
    if (IS_BINARY_REDUCE) {
#if @PW@
        @type@ * iop1 = (@type@ *)args[0];
        npy_intp n = dimensions[0];

        *iop1 @OP@= @TYPE@_pairwise_sum(args[1], n, steps[1]);
#else
        BINARY_REDUCE_LOOP(@type@) {
            io1 @OP@= *(@type@ *)ip2;
        }
        *((@type@ *)iop1) = io1;
#endif
    }
    else if (!run_binary_simd_@kind@_@TYPE@(args, dimensions, steps)) {
        BINARY_LOOP {
            const @type@ in1 = *(@type@ *)ip1;
            const @type@ in2 = *(@type@ *)ip2;
            *((@type@ *)op1) = in1 @OP@ in2;
        }
    }
}
/**end repeat1**/
/**end repeat**/
						</code></pre>
					</div>
				</div>

				<aside class="notes">

				</aside>
			</section>

			<section>

				<!-- NOTE: the following are non-presentation elements used for driving the SVG animations -->
				<span class="fragment"></span>
				<span class="fragment"></span>
				<span class="fragment"></span>

				<div data-animate data-src="img/layers_schematic.svg">
					<!--
					{
						"setup": [
							{
								"element": "#top-layer",
								"modifier": "attr",
								"parameters": [ {"class": "fragment", "data-fragment-index": "0"} ]
							},
							{
								"element": "#middle-layer",
								"modifier": "attr",
								"parameters": [ {"class": "fragment", "data-fragment-index": "1"} ]
							},
							{
								"element": "#bottom-layer",
								"modifier": "attr",
								"parameters": [ {"class": "fragment", "data-fragment-index": "2"} ]
							}
						]
					}
					-->
				</div>

				<aside class="notes">
					<p>
						TODO: finish schematic
					</p>
				</aside>
			</section>

		</div> <!-- /.slides -->
	</div> <!-- /.reveal -->

	<script src="node_modules/reveal.js/dist/reveal.js"></script>
	<script src="node_modules/reveal.js/plugin/notes/notes.js"></script>
	<script src="node_modules/reveal.js/plugin/highlight/highlight.js"></script>
	<script src="node_modules/reveal.js/plugin/search/search.js"></script>
	<script src="node_modules/reveal.js/plugin/math/math.js"></script>
	<script src="node_modules/reveal.js-appearance/plugin/appearance/appearance.js"></script>

	<script src="js/plugins/animate/plugin.js"></script>
	<script src="js/plugins/animate/svg.js"></script>

	<script>
		Reveal.initialize({
			// Hide the controls:
			'controls': false,

			// Show slide numbers in the speaker view:
			'showSlideNumber': 'speaker',

			// Add the current slide number to the URL hash so that reloading the page/copying the URL will return you to the same slide:
			'hash': true,

			// Only use left/right arrows to navigate slides:
			'navigationMode': 'linear',

			// Hide the presentation progress bar:
			'progress': false,

			// Disable the default layout (scaling and centering):
			'disableLayout': true,

			// Disable vertical centering:
			'center': false,

			// Specify the default transition style:
			'transition': 'slide',

			// Configure PDF export to not display fragments as separate pages:
			'pdfSeparateFragments': false,

			// Ensure that slides do not spread across multiple pages:
			'pdfMaxPagesPerSlide': 1,

			// Configure the Appearance plugin:
			'appearance': {
				// Display the elements when moving backward in the presentation:
				'hideagain': false
			},

			// Configure the plugin for rendering mathematical equations:
			'math': {
				'mathjax': 'node_modules/mathjax/es5/tex-mml-chtml.js',

				'config': 'TeX-AMS_HTML-full',

				'TeX': {
					'inlineMath': [
						[ '$', '$' ],
						[ '\\(', '\\)' ]
					]
				}
			},

			// Specify a list of plugins:
			'plugins': [
				// Syntax highlight code:
				RevealHighlight,

				// Enable speaker notes:
				RevealNotes,

				// Enable searching across slides via CTRL+SHIFT+F:
				RevealSearch,

				// Render mathematical equations:
				RevealMath,

				// Enable animations:
				Appearance,

				// Enable SVG animations:
				RevealAnimate
			]
		});
	</script>
	<script src="js/script.js"></script>
</body>
</html>
